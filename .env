# ============================================================
#  KoalaqVision Environment Configuration
# ============================================================

# ============================================================
# Application Configuration
# ============================================================
# Application mode: "object" or "face"
#   - object: Object recognition mode (DINOv3, 1024-dim vectors)
#   - face:   Face recognition mode (InsightFace, 512-dim vectors)
APP_MODE=object

# ============================================================
# API Service Configuration
# ============================================================
# API server port
API_PORT=10770

# API server host
# - 0.0.0.0: IPv4 only
# - ::: IPv6 (and IPv4 on most systems)
API_HOST=0.0.0.0

# ============================================================
# Vector Database Configuration
# ============================================================
# Weaviate vector database URL
WEAVIATE_URL=http://localhost:10769

# Weaviate API key (optional, uncomment if needed)
# WEAVIATE_API_KEY=your_api_key_here

# ============================================================
# File Storage Configuration
# ============================================================
# Upload files directory
UPLOAD_PATH=data/upload

# Temporary files directory
TEMP_PATH=data/temp

# ============================================================
# Model Configuration - Object Mode
# ============================================================
# Object recognition backend: onnx / pytorch
#   - onnx:    CPU optimized, lightweight, fast (recommended for production)
#   - pytorch: GPU accelerated, high precision (requires CUDA, for development/training)
OBJECT_BACKEND=onnx

# Background removal model paths (ONNX backend)
BIREFNET_MODEL_PATH=data/models/BiRefNet/model_fp16.onnx
U2NET_MODEL_PATH=data/models/U2Net/u2net.onnx
U2NETP_MODEL_PATH=data/models/U2Net/u2netp.onnx

# Background removal model selection: birefnet / u2net / u2netp
#   - u2netp:  Fastest, smallest (4.7MB, ~50ms) - Recommended
#   - u2net:   Balanced (168MB, ~100ms)
#   - birefnet: Best quality (230MB, ~4s)
BG_REMOVAL_MODEL=u2net

# DINOv3 model selection (Simple Mode - Recommended)
# Preset models: vits16 / vitl16
#   - vits16: Fast, lightweight (83MB, ~0.3s, 384-dim)
#   - vitl16: Best accuracy (185MB, ~1s, 1024-dim) - Recommended
DINOV3_MODEL=vitl16

# DINOv3 model path (Advanced Mode)
# Leave DINOV3_MODEL empty to use custom path
# DINOV3_MODEL_PATH=data/models/dinov3-vitl16/model_q4.onnx

# PyTorch backend model paths (when OBJECT_BACKEND=pytorch)
PYTORCH_BIREFNET_PATH=data/models/BiRefNet
PYTORCH_DINOV3_PATH=data/models/dinov3-vith16plus-pretrain-lvd1689m

# DINOv3 Feature Extraction Optimization (for PyTorch backend)
#   - Temperature scaling: Lower values (0.1-0.5) increase feature discrimination
#   - Multi-scale fusion: Combine global (CLS) and local (patch) features
#   - Feature enhancement: Apply L2 normalization (not standardization)
DINOV3_TEMPERATURE=0.3
DINOV3_USE_MULTI_SCALE=true
DINOV3_CLS_WEIGHT=0.7
DINOV3_PATCH_WEIGHT=0.3
DINOV3_FEATURE_ENHANCEMENT=true

# ============================================================
# Model Configuration - Face Mode
# ============================================================
# Face recognition model name (InsightFace)
# Default: buffalo_s (159MB, 512-dim) - Balanced performance
# Upgrade options (see docs/model-upgrade-guide.md):
#   - buffalo_l (326MB) - Best accuracy
FACE_MODEL_NAME=antelopev2

# Face model root directory
FACE_MODEL_ROOT=data/models

# Face detection confidence threshold [0.0-1.0]
#   - 0.3: Relaxed mode (Recommended) - Detects more faces including glasses, side faces, low light
#   - 0.5: Default mode - InsightFace original default, stricter
#   - 0.7: Strict mode - Only high-quality faces
FACE_DET_THRESH=0.3

# Enable multi-scale face detection (solves large face/close-up detection failures)
# SCRFD performs poorly on large faces (>40% of image), multi-scale enables auto-retry
#   - Primary detection size: 640x640 (suitable for normal scenes)
#   - Fallback detection size: 256x256 (suitable for large faces/close-ups)
FACE_ENABLE_MULTI_SCALE=true

# Enable liveness detection (anti-spoofing)
ENABLE_LIVENESS=true

# Liveness detection threshold (real face score) [0.0-1.0]
# Relaxed strategy: Only reject obviously fake faces
#   - Lower threshold (0.4) makes it easier to pass verification
LIVENESS_THRESHOLD=0.4

# Paper photo rejection threshold [0.0-1.0]
#   - Higher threshold (0.7) means only obvious paper photos are rejected
#   - Only reject when paper_score > 0.7
LIVENESS_PAPER_REJECT_THRESHOLD=0.7

# Electronic screen rejection threshold [0.0-1.0]
#   - Higher threshold (0.7) means only obvious screens are rejected
#   - Only reject when screen_score > 0.7
LIVENESS_SCREEN_REJECT_THRESHOLD=0.7

# MiniFASNet liveness model directory
MINIFASNET_MODEL_DIR=data/models/minifasnet

# ============================================================
# Model Runtime Configuration
# ============================================================
# Enable GPU acceleration (set to true if GPU available)
USE_GPU=false

# ONNX Runtime threading optimization mode (for ONNX backend)
# Options:
#   - auto:        Balanced mode (intra=0, inter=0, SEQUENTIAL) - Recommended for most scenarios
#                  Automatically optimizes based on CPU cores with thread affinity
#   - performance: Low latency mode (intra=0, inter=0, PARALLEL) - For single requests or low concurrency
#                  Uses parallel execution for faster individual responses
#   - single:      High concurrency mode (intra=1, inter=1, SEQUENTIAL) - For web servers with high traffic
#                  Single-thread per session reduces thread competition, improves total throughput by ~50%
ONNX_THREAD_MODE=auto

# ============================================================
# SSL/HTTPS Configuration
# ============================================================
# Enable HTTPS (requires SSL certificates in SSL_CERT_DIR)
ENABLE_SSL=false

# SSL certificate directory (auto-discover cert and key files)
# Supports: fullchain.pem/privkey.pem, cert.pem/key.pem, *.crt/*.key, etc.
SSL_CERT_DIR=./data/certs

# ============================================================
# Debug & Logging Configuration
# ============================================================
# Enable debug mode
DEBUG=false

# Enable auto-reload on code changes (development only)
RELOAD=false

# Logger output style: "block" or "tree"
LOG_STYLE=tree